# ina-backend/test_report_complete.py - TEST SIN DEPENDENCIAS
import os
import sys
import tempfile

# Configurar path para importar desde la carpeta app
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'app'))

try:
    from models import init_db, get_db_summary, engine
    from analytics import get_period_analytics, get_detailed_period_stats
    from metrics_tracker import metrics_tracker
    from report_generator import report_generator
    from pdf_generator import pdf_generator
    IMPORT_SUCCESS = True
except ImportError as e:
    print(f"âŒ Error importando mÃ³dulos: {e}")
    IMPORT_SUCCESS = False

class TestReportSystem:
    """Test completo del sistema de reportes PDF - SIN pytest"""
    
    def setup_method(self):
        """ConfiguraciÃ³n antes de cada test"""
        os.makedirs("instance", exist_ok=True)
    
    def test_01_database_initialization(self):
        """Test 1: Verificar que la base de datos se inicializa correctamente"""
        print("\nğŸ”§ TEST 1: InicializaciÃ³n de Base de Datos")
        
        try:
            # Inicializar BD
            init_db()
            
            # Verificar que la BD existe
            assert os.path.exists("instance/database.db"), "âŒ La base de datos no se creÃ³"
            print("âœ… Base de datos creada correctamente")
            
            # Verificar resumen de datos
            summary = get_db_summary()
            assert "error" not in summary, f"âŒ Error en resumen: {summary['error']}"
            
            print(f"âœ… Datos de ejemplo insertados:")
            print(f"   - Consultas: {summary['user_queries']}")
            print(f"   - Feedback: {summary['feedback']}")
            print(f"   - No respondidas: {summary['unanswered_questions']}")
            return True
            
        except Exception as e:
            print(f"âŒ Error en test 1: {e}")
            return False
    
    def test_02_analytics_basic_metrics(self):
        """Test 2: Verificar mÃ©tricas bÃ¡sicas de analytics"""
        print("\nğŸ“Š TEST 2: MÃ©tricas BÃ¡sicas de Analytics")
        
        try:
            # Obtener analytics para 30 dÃ­as
            analytics_data = get_period_analytics(30)
            
            # Verificar estructura bÃ¡sica
            required_keys = ["period_days", "start_date", "end_date", "summary_metrics", "categories"]
            for key in required_keys:
                assert key in analytics_data, f"âŒ Falta clave: {key}"
            
            # Verificar mÃ©tricas especÃ­ficas
            summary = analytics_data["summary_metrics"]
            
            assert summary["total_queries"] == 51, f"âŒ Total consultas incorrecto: {summary['total_queries']}"
            assert summary["unanswered_questions"] == 1, f"âŒ No respondidas incorrecto: {summary['unanswered_questions']}"
            assert summary["total_feedback"] == 26, f"âŒ Total feedback incorrecto: {summary['total_feedback']}"
            
            print("âœ… Estructura de analytics correcta")
            print(f"âœ… MÃ©tricas bÃ¡sicas verificadas:")
            print(f"   - Total consultas: {summary['total_queries']}")
            print(f"   - No respondidas: {summary['unanswered_questions']}")
            print(f"   - Feedback: {summary['total_feedback']}")
            print(f"   - SatisfacciÃ³n: {summary['satisfaction_rate']}%")
            print(f"   - Respuesta: {summary['response_rate']}%")
            return True
            
        except Exception as e:
            print(f"âŒ Error en test 2: {e}")
            return False
    
    def test_03_analytics_categories(self):
        """Test 3: Verificar categorÃ­as en analytics"""
        print("\nğŸ¯ TEST 3: AnÃ¡lisis de CategorÃ­as")
        
        try:
            analytics_data = get_period_analytics(30)
            categories = analytics_data["categories"]
            
            # Verificar categorÃ­as especÃ­ficas del reporte
            expected_categories = ["horarios", "certificados", "acadÃ©mico", "otros", "tnÃ©"]
            
            for category in expected_categories:
                assert category in categories, f"âŒ Falta categorÃ­a: {category}"
                assert categories[category] > 0, f"âŒ Conteo 0 para {category}: {categories[category]}"
            
            print("âœ… CategorÃ­as verificadas correctamente:")
            for category, count in categories.items():
                print(f"   - {category}: {count} consultas")
            return True
            
        except Exception as e:
            print(f"âŒ Error en test 3: {e}")
            return False
    
    def test_04_advanced_metrics_tracker(self):
        """Test 4: Verificar mÃ©tricas avanzadas"""
        print("\nğŸš€ TEST 4: MÃ©tricas Avanzadas")
        
        try:
            # Obtener mÃ©tricas avanzadas
            advanced_metrics = metrics_tracker.get_advanced_metrics(30)
            
            # Verificar estructura
            required_sections = ["temporal_analysis", "category_analysis", "recurrent_questions", "performance_metrics"]
            for section in required_sections:
                assert section in advanced_metrics, f"âŒ Falta secciÃ³n: {section}"
            
            print("âœ… Estructura de mÃ©tricas avanzadas correcta")
            
            # Verificar anÃ¡lisis temporal
            temporal = advanced_metrics["temporal_analysis"]
            assert temporal["hourly"]["peak_hour"] != "N/A", "âŒ Hora pico es N/A"
            assert temporal["daily"]["busiest_day"] != "N/A", "âŒ DÃ­a mÃ¡s activo es N/A"
            
            print("âœ… AnÃ¡lisis temporal con datos reales:")
            print(f"   - Hora pico: {temporal['hourly']['peak_hour']}")
            print(f"   - DÃ­a mÃ¡s activo: {temporal['daily']['busiest_day']}")
            print(f"   - Tendencia: {temporal['trends']['trend_direction']} {temporal['trends']['trend_percentage']}%")
            
            # Verificar categorÃ­as avanzadas
            category_analysis = advanced_metrics["category_analysis"]
            assert len(category_analysis) > 0, "âŒ No hay anÃ¡lisis de categorÃ­as"
            
            print("âœ… AnÃ¡lisis de categorÃ­as avanzado:")
            for category, data in list(category_analysis.items())[:3]:
                print(f"   - {category}: {data['count']} consultas, rating {data['avg_rating']}/5")
            
            # Verificar preguntas recurrentes
            recurrent_questions = advanced_metrics["recurrent_questions"]
            assert len(recurrent_questions) > 0, "âŒ No hay preguntas recurrentes"
            
            print("âœ… Preguntas recurrentes encontradas:")
            for i, question in enumerate(recurrent_questions[:3], 1):
                print(f"   {i}. '{question['question']}' ({question['count']} veces)")
            
            return True
            
        except Exception as e:
            print(f"âŒ Error en test 4: {e}")
            return False
    
    def test_05_report_generation(self):
        """Test 5: Verificar generaciÃ³n de reportes"""
        print("\nğŸ“„ TEST 5: GeneraciÃ³n de Reportes")
        
        try:
            # Generar reporte bÃ¡sico
            report_data = report_generator.generate_basic_report(30)
            
            # Verificar estructura del reporte
            required_sections = [
                "report_metadata", 
                "summary_metrics", 
                "categorias_populares",
                "feedback_detallado", 
                "problemas_comunes",
                "advanced_metrics"
            ]
            
            for section in required_sections:
                assert section in report_data, f"âŒ Falta secciÃ³n en reporte: {section}"
            
            print("âœ… Estructura de reporte correcta")
            
            # Verificar que las mÃ©tricas avanzadas estÃ©n incluidas
            assert "advanced_metrics" in report_data, "âŒ No se incluyeron mÃ©tricas avanzadas en el reporte"
            
            advanced_metrics = report_data["advanced_metrics"]
            assert "temporal_analysis" in advanced_metrics, "âŒ No hay anÃ¡lisis temporal en reporte"
            assert "category_analysis" in advanced_metrics, "âŒ No hay anÃ¡lisis de categorÃ­as en reporte"
            
            print("âœ… MÃ©tricas avanzadas incluidas en el reporte")
            
            # Verificar datos especÃ­ficos del reporte
            summary = report_data["summary_metrics"]
            assert summary["total_consultas"] == 51, f"âŒ Total consultas reporte incorrecto: {summary['total_consultas']}"
            assert summary["consultas_sin_respuesta"] == 1, f"âŒ Consultas sin respuesta incorrecto: {summary['consultas_sin_respuesta']}"
            
            print("âœ… Datos del reporte verificados:")
            print(f"   - Total consultas: {summary['total_consultas']}")
            print(f"   - Sin respuesta: {summary['consultas_sin_respuesta']}")
            print(f"   - Tasa respuesta: {summary['tasa_respuesta']}%")
            print(f"   - Tasa satisfacciÃ³n: {summary['tasa_satisfaccion']}%")
            return True
            
        except Exception as e:
            print(f"âŒ Error en test 5: {e}")
            return False
    
    def test_06_pdf_generation(self):
        """Test 6: Verificar generaciÃ³n de PDF"""
        print("\nğŸ“Š TEST 6: GeneraciÃ³n de PDF con MÃ©tricas Avanzadas")
        
        try:
            # Generar reporte primero
            report_data = report_generator.generate_basic_report(30)
            
            # Crear archivo PDF temporal
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
                pdf_path = temp_file.name
            
            try:
                # Generar PDF
                result_path = pdf_generator.generate_report_pdf(report_data, pdf_path)
                
                # Verificar que se creÃ³ el PDF
                assert os.path.exists(result_path), "âŒ No se creÃ³ el archivo PDF"
                assert os.path.getsize(result_path) > 1000, "âŒ PDF demasiado pequeÃ±o"
                
                print("âœ… PDF generado correctamente")
                print(f"   - Ruta: {result_path}")
                print(f"   - TamaÃ±o: {os.path.getsize(result_path)} bytes")
                
                return True
                
            finally:
                # Limpiar archivo temporal
                if os.path.exists(pdf_path):
                    os.remove(pdf_path)
                    
        except Exception as e:
            print(f"âŒ Error en test 6: {e}")
            return False
    
    def test_07_detailed_analytics(self):
        """Test 7: Verificar analytics detallados"""
        print("\nğŸ“ˆ TEST 7: Analytics Detallados")
        
        try:
            detailed_stats = get_detailed_period_stats(30)
            
            # Verificar que incluye mÃ©tricas detalladas
            assert "detailed_metrics" in detailed_stats, "âŒ No hay mÃ©tricas detalladas"
            
            detailed_metrics = detailed_stats["detailed_metrics"]
            required_detailed = ["daily_activity", "problematic_categories", "period_comparison"]
            
            for metric in required_detailed:
                assert metric in detailed_metrics, f"âŒ Falta mÃ©trica detallada: {metric}"
            
            print("âœ… Analytics detallados verificados:")
            print(f"   - DÃ­as con actividad: {len(detailed_metrics['daily_activity'])}")
            print(f"   - CategorÃ­as problemÃ¡ticas: {len(detailed_metrics['problematic_categories'])}")
            print(f"   - Crecimiento: {detailed_metrics['period_comparison']['query_growth']}%")
            return True
            
        except Exception as e:
            print(f"âŒ Error en test 7: {e}")
            return False
    
    def test_08_integration_complete_flow(self):
        """Test 8: Flujo completo de integraciÃ³n"""
        print("\nğŸ”„ TEST 8: Flujo Completo de IntegraciÃ³n")
        
        try:
            # Paso 1: Obtener analytics
            analytics = get_detailed_period_stats(30)
            print("âœ… Paso 1: Analytics obtenidos")
            
            # Paso 2: Generar reporte
            report = report_generator.generate_basic_report(30)
            print("âœ… Paso 2: Reporte generado")
            
            # Paso 3: Verificar que el reporte incluye analytics
            assert report["summary_metrics"]["total_consultas"] == analytics["summary_metrics"]["total_queries"]
            print("âœ… Paso 3: Datos de analytics integrados en reporte")
            
            # Paso 4: Verificar mÃ©tricas avanzadas en reporte
            assert "advanced_metrics" in report, "âŒ No hay mÃ©tricas avanzadas en reporte"
            advanced = report["advanced_metrics"]
            
            # Verificar que las mÃ©tricas avanzadas tienen datos reales
            assert advanced["temporal_analysis"]["hourly"]["peak_hour"] != "N/A"
            assert advanced["category_analysis"] != {}
            assert advanced["recurrent_questions"] != []
            
            print("âœ… Paso 4: MÃ©tricas avanzadas integradas y con datos reales")
            
            # Paso 5: Generar PDF
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_file:
                pdf_path = temp_file.name
            
            try:
                pdf_result = pdf_generator.generate_report_pdf(report, pdf_path)
                assert os.path.exists(pdf_result)
                assert os.path.getsize(pdf_result) > 1000
                print("âœ… Paso 5: PDF generado exitosamente")
                
            finally:
                if os.path.exists(pdf_path):
                    os.remove(pdf_path)
            
            print("ğŸ‰ FLUJO COMPLETO VERIFICADO: BD â†’ Analytics â†’ Reporte â†’ PDF")
            return True
            
        except Exception as e:
            print(f"âŒ Error en test 8: {e}")
            return False

def run_complete_test_suite():
    """Ejecutar suite completa de tests"""
    print("=" * 70)
    print("ğŸ§ª TEST COMPLETO DEL SISTEMA DE REPORTES PDF")
    print("ğŸ“ UbicaciÃ³n: ina-backend/test_report_complete.py")
    print("=" * 70)
    
    if not IMPORT_SUCCESS:
        print("âŒ No se pudieron importar los mÃ³dulos necesarios")
        return False
    
    test_instance = TestReportSystem()
    test_instance.setup_method()
    
    tests = [
        test_instance.test_01_database_initialization,
        test_instance.test_02_analytics_basic_metrics,
        test_instance.test_03_analytics_categories,
        test_instance.test_04_advanced_metrics_tracker,
        test_instance.test_05_report_generation,
        test_instance.test_06_pdf_generation,
        test_instance.test_07_detailed_analytics,
        test_instance.test_08_integration_complete_flow
    ]
    
    passed_tests = 0
    total_tests = len(tests)
    
    for i, test in enumerate(tests, 1):
        try:
            if test():
                passed_tests += 1
        except Exception as e:
            print(f"âŒ Test {i} fallÃ³ con excepciÃ³n: {e}")
    
    print("\n" + "=" * 70)
    print(f"ğŸ“Š RESULTADO: {passed_tests}/{total_tests} tests pasaron")
    
    if passed_tests == total_tests:
        print("ğŸ‰ Â¡TODOS LOS TESTS PASARON EXITOSAMENTE!")
        print("ğŸš€ El sistema de reportes estÃ¡ listo para producciÃ³n!")
    else:
        print("âš ï¸ Algunos tests fallaron, revisa los errores arriba")
    
    print("=" * 70)
    return passed_tests == total_tests

if __name__ == "__main__":
    # Ejecutar tests
    success = run_complete_test_suite()
    
    # Salir con cÃ³digo apropiado
    sys.exit(0 if success else 1)