#!/usr/bin/env python3
"""
enhanced_rag_system.py
Sistema RAG Mejorado para IA Institucional DUOC UC

Mejoras implementadas:
1. Retrieval h√≠brido (sem√°ntico + l√©xico + contextual)
2. Re-ranking inteligente de documentos
3. Generaci√≥n contextual mejorada
4. Fusion de m√∫ltiples fuentes de informaci√≥n
5. Sistema de confianza y validaci√≥n
6. Respuestas m√°s naturales y conversacionales
"""

import numpy as np
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime
import json
import re
from collections import defaultdict, Counter
import hashlib

# Librer√≠as para RAG avanzado
from sentence_transformers import SentenceTransformer, CrossEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import faiss

# Importar m√≥dulos existentes del proyecto
try:
    from app.rag import rag_engine
    from app.cache_manager import rag_cache, response_cache
    from app.topic_classifier import TopicClassifier
except ImportError as e:
    logging.warning(f"Algunos m√≥dulos del proyecto no est√°n disponibles: {e}")

logger = logging.getLogger(__name__)

@dataclass
class RetrievedDocument:
    """Documento recuperado con metadata enriquecida"""
    content: str
    metadata: Dict[str, Any]
    semantic_score: float
    lexical_score: float
    context_score: float
    final_score: float
    confidence: float
    source_priority: str
    relevance_explanation: str

@dataclass
class ResponseContext:
    """Contexto para generar respuesta"""
    query: str
    category: str
    retrieved_docs: List[RetrievedDocument]
    conversation_history: List[Dict] = None
    user_intent: str = ""
    confidence_threshold: float = 0.6

class AdvancedRetriever:
    """Retriever h√≠brido avanzado"""
    
    def __init__(self):
        # Modelos de embeddings especializados
        self.embedders = self._load_embedders()
        
        # TF-IDF vectorizer para b√∫squeda l√©xica
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=10000,
            ngram_range=(1, 3),
            stop_words=self._get_spanish_stopwords(),
            lowercase=True
        )
        self.tfidf_matrix = None
        self.documents_corpus = []
        self.documents_metadata = []
        
        # Cross-encoder para re-ranking
        try:
            self.cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')
            logger.info("‚úÖ Cross-encoder cargado para re-ranking")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Cross-encoder no disponible: {e}")
            self.cross_encoder = None
            
        # √çndice FAISS para b√∫squeda sem√°ntica r√°pida
        self.faiss_index = None
        self.document_embeddings = []
        
        # Clasificador de intenciones
        self.intent_classifier = TopicClassifier()
        
    def _load_embedders(self) -> Dict[str, SentenceTransformer]:
        """Carga m√∫ltiples modelos de embeddings especializados"""
        
        embedders = {}
        
        models_config = {
            'multilingual': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
            'spanish': 'sentence-transformers/distiluse-base-multilingual-cased', 
            'semantic_search': 'sentence-transformers/all-MiniLM-L6-v2'
        }
        
        for name, model_path in models_config.items():
            try:
                embedders[name] = SentenceTransformer(model_path)
                logger.info(f"‚úÖ Modelo {name} cargado correctamente")
            except Exception as e:
                logger.error(f"‚ùå Error cargando modelo {name}: {e}")
                
        return embedders

    def _get_spanish_stopwords(self) -> List[str]:
        """Obtiene stopwords en espa√±ol personalizadas"""
        
        basic_stopwords = [
            'el', 'la', 'de', 'que', 'y', 'a', 'en', 'un', 'es', 'se', 'no', 'te', 'lo', 'le', 'da', 'su', 'por', 'son', 
            'con', 'para', 'al', 'del', 'los', 'las', 'una', 'pero', 'sus', 'muy', 'sin', 'sobre', 'ser', 'tener', 
            'todo', 'esta', 'estar', 'como', 'hacer', 'puede', 'm√°s', 'si', 'ya', 'o', 'entre', 'hasta', 'cuando',
            'donde', 'quien', 'cual', 'qu√©', 'c√≥mo', 'd√≥nde', 'cu√°ndo', 'por qu√©'
        ]
        
        # Agregar stopwords espec√≠ficas de contexto institucional
        institutional_stopwords = [
            'duoc', 'uc', 'universidad', 'instituci√≥n', 'centro', 'sede', 'campus'
        ]
        
        return basic_stopwords + institutional_stopwords

    def index_documents(self, documents: List[Dict[str, Any]]):
        """Indexa documentos para b√∫squeda h√≠brida"""
        
        logger.info(f"üîÑ Indexando {len(documents)} documentos...")
        
        # Preparar corpus para TF-IDF
        self.documents_corpus = []
        self.documents_metadata = []
        
        for doc in documents:
            self.documents_corpus.append(doc.get('content', ''))
            self.documents_metadata.append(doc.get('metadata', {}))
            
        # Entrenar TF-IDF vectorizer
        try:
            self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.documents_corpus)
            logger.info(f"‚úÖ TF-IDF matrix creada: {self.tfidf_matrix.shape}")
        except Exception as e:
            logger.error(f"‚ùå Error creando TF-IDF matrix: {e}")
            
        # Crear embeddings sem√°nticos
        self._create_semantic_index()
        
        logger.info("‚úÖ Indexaci√≥n de documentos completada")

    def _create_semantic_index(self):
        """Crea √≠ndice FAISS para b√∫squeda sem√°ntica"""
        
        if not self.embedders or not self.documents_corpus:
            return
            
        try:
            # Usar modelo multiling√ºe principal para indexaci√≥n
            primary_embedder = self.embedders.get('multilingual') or list(self.embedders.values())[0]
            
            # Generar embeddings para todos los documentos
            document_embeddings = primary_embedder.encode(
                self.documents_corpus,
                batch_size=32,
                show_progress_bar=True
            )
            
            self.document_embeddings = document_embeddings
            
            # Crear √≠ndice FAISS
            dimension = document_embeddings.shape[1]
            self.faiss_index = faiss.IndexFlatIP(dimension)  # Inner Product para cosine similarity
            
            # Normalizar embeddings para cosine similarity
            normalized_embeddings = document_embeddings / np.linalg.norm(document_embeddings, axis=1, keepdims=True)
            self.faiss_index.add(normalized_embeddings.astype('float32'))
            
            logger.info(f"‚úÖ √çndice FAISS creado con {self.faiss_index.ntotal} documentos")
            
        except Exception as e:
            logger.error(f"‚ùå Error creando √≠ndice sem√°ntico: {e}")

    def retrieve_hybrid(self, query: str, top_k: int = 15) -> List[RetrievedDocument]:
        """Retrieval h√≠brido combinando m√∫ltiples estrategias"""
        
        # Paso 1: Retrieval sem√°ntico
        semantic_results = self._semantic_search(query, top_k)
        
        # Paso 2: Retrieval l√©xico (TF-IDF)
        lexical_results = self._lexical_search(query, top_k)
        
        # Paso 3: Retrieval contextual (basado en categor√≠a/intenci√≥n)
        context_results = self._contextual_search(query, top_k)
        
        # Paso 4: Fusionar resultados
        fused_results = self._fuse_results(semantic_results, lexical_results, context_results, query)
        
        # Paso 5: Re-ranking con cross-encoder si est√° disponible
        if self.cross_encoder and len(fused_results) > 1:
            reranked_results = self._rerank_documents(query, fused_results)
        else:
            reranked_results = fused_results
            
        # Paso 6: Filtrar por calidad y diversidad
        final_results = self._filter_and_diversify(reranked_results, top_k=min(top_k, 8))
        
        logger.info(f"üîç Retrieval h√≠brido: {len(final_results)} documentos recuperados para '{query[:50]}...'")
        
        return final_results

    def _semantic_search(self, query: str, top_k: int) -> List[Tuple[int, float, str]]:
        """B√∫squeda sem√°ntica usando embeddings"""
        
        if not self.faiss_index or not self.embedders:
            return []
            
        try:
            # Usar modelo principal para la query
            primary_embedder = self.embedders.get('multilingual') or list(self.embedders.values())[0]
            
            # Generar embedding de la consulta
            query_embedding = primary_embedder.encode([query])
            query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)
            
            # B√∫squeda en FAISS
            scores, indices = self.faiss_index.search(query_embedding.astype('float32'), top_k * 2)
            
            # Formatear resultados
            semantic_results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx >= len(self.documents_corpus):
                    continue
                    
                semantic_results.append((idx, float(score), 'semantic'))
                
            return semantic_results
            
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda sem√°ntica: {e}")
            return []

    def _lexical_search(self, query: str, top_k: int) -> List[Tuple[int, float, str]]:
        """B√∫squeda l√©xica usando TF-IDF"""
        
        if self.tfidf_matrix is None:
            return []
            
        try:
            # Vectorizar query
            query_vector = self.tfidf_vectorizer.transform([query])
            
            # Calcular similitudes
            similarities = cosine_similarity(query_vector, self.tfidf_matrix)[0]
            
            # Obtener top resultados
            top_indices = np.argsort(similarities)[::-1][:top_k * 2]
            
            lexical_results = []
            for idx in top_indices:
                if similarities[idx] > 0.01:  # Umbral m√≠nimo
                    lexical_results.append((idx, similarities[idx], 'lexical'))
                    
            return lexical_results
            
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda l√©xica: {e}")
            return []

    def _contextual_search(self, query: str, top_k: int) -> List[Tuple[int, float, str]]:
        """B√∫squeda contextual basada en categor√≠a e intenci√≥n"""
        
        try:
            # Clasificar intenci√≥n/categor√≠a de la query
            classification = self.intent_classifier.classify_topic(query)
            category = classification.get('category', 'general')
            confidence = classification.get('confidence', 0.0)
            
            contextual_results = []
            
            # Buscar documentos de la misma categor√≠a
            for i, metadata in enumerate(self.documents_metadata):
                doc_category = metadata.get('category', 'general')
                
                # Score basado en coincidencia de categor√≠a
                category_score = 0.0
                if doc_category == category:
                    category_score = confidence * 0.8
                elif category in doc_category or doc_category in category:
                    category_score = confidence * 0.6
                    
                # Bonus para documentos de alta prioridad
                priority = metadata.get('priority', 'medium')
                priority_bonus = {'high': 0.2, 'medium': 0.1, 'low': 0.0}.get(priority, 0.0)
                
                # Bonus para contenido Plaza Norte espec√≠fico
                plaza_norte_bonus = 0.15 if metadata.get('is_plaza_norte', False) else 0.0
                
                total_score = category_score + priority_bonus + plaza_norte_bonus
                
                if total_score > 0.1:
                    contextual_results.append((i, total_score, 'contextual'))
                    
            # Ordenar por score
            contextual_results.sort(key=lambda x: x[1], reverse=True)
            
            return contextual_results[:top_k]
            
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda contextual: {e}")
            return []

    def _fuse_results(self, semantic_results: List[Tuple], lexical_results: List[Tuple], 
                     context_results: List[Tuple], query: str) -> List[RetrievedDocument]:
        """Fusiona resultados de m√∫ltiples estrategias de b√∫squeda"""
        
        # Combinar todos los resultados
        all_results = defaultdict(lambda: {'semantic': 0.0, 'lexical': 0.0, 'contextual': 0.0})
        
        # Procesar resultados sem√°nticos
        for idx, score, result_type in semantic_results:
            all_results[idx]['semantic'] = score
            
        # Procesar resultados l√©xicos
        for idx, score, result_type in lexical_results:
            all_results[idx]['lexical'] = score
            
        # Procesar resultados contextuales
        for idx, score, result_type in context_results:
            all_results[idx]['contextual'] = score
            
        # Crear objetos RetrievedDocument
        retrieved_docs = []
        
        for doc_idx, scores in all_results.items():
            if doc_idx >= len(self.documents_corpus):
                continue
                
            # Calcular score final ponderado
            semantic_weight = 0.5
            lexical_weight = 0.3
            contextual_weight = 0.2
            
            final_score = (
                scores['semantic'] * semantic_weight +
                scores['lexical'] * lexical_weight +
                scores['contextual'] * contextual_weight
            )
            
            # Calcular confianza
            confidence = self._calculate_confidence(scores, query, doc_idx)
            
            # Crear documento recuperado
            doc = RetrievedDocument(
                content=self.documents_corpus[doc_idx],
                metadata=self.documents_metadata[doc_idx],
                semantic_score=scores['semantic'],
                lexical_score=scores['lexical'],
                context_score=scores['contextual'],
                final_score=final_score,
                confidence=confidence,
                source_priority=self.documents_metadata[doc_idx].get('priority', 'medium'),
                relevance_explanation=self._generate_relevance_explanation(scores, query)
            )
            
            retrieved_docs.append(doc)
            
        # Ordenar por score final
        retrieved_docs.sort(key=lambda x: x.final_score, reverse=True)
        
        return retrieved_docs

    def _calculate_confidence(self, scores: Dict[str, float], query: str, doc_idx: int) -> float:
        """Calcula confianza en la relevancia del documento"""
        
        confidence = 0.0
        
        # Factor 1: Consistencia entre diferentes m√©todos de b√∫squeda
        active_scores = [score for score in scores.values() if score > 0]
        if len(active_scores) > 1:
            score_variance = np.var(active_scores)
            consistency_bonus = max(0, 0.3 - score_variance)
            confidence += consistency_bonus
            
        # Factor 2: Score absoluto
        max_score = max(scores.values())
        confidence += max_score * 0.4
        
        # Factor 3: Metadata quality
        metadata = self.documents_metadata[doc_idx]
        if metadata.get('priority') == 'high':
            confidence += 0.2
        if metadata.get('is_plaza_norte', False):
            confidence += 0.1
            
        # Factor 4: Longitud apropiada del contenido
        content_length = len(self.documents_corpus[doc_idx])
        if 200 <= content_length <= 2000:
            confidence += 0.1
            
        return min(confidence, 1.0)

    def _generate_relevance_explanation(self, scores: Dict[str, float], query: str) -> str:
        """Genera explicaci√≥n de por qu√© el documento es relevante"""
        
        explanations = []
        
        if scores['semantic'] > 0.5:
            explanations.append("alta similitud sem√°ntica")
        elif scores['semantic'] > 0.3:
            explanations.append("similitud sem√°ntica moderada")
            
        if scores['lexical'] > 0.3:
            explanations.append("coincidencias de t√©rminos clave")
            
        if scores['contextual'] > 0.4:
            explanations.append("categor√≠a relevante")
            
        return ", ".join(explanations) if explanations else "relevancia general"

    def _rerank_documents(self, query: str, documents: List[RetrievedDocument]) -> List[RetrievedDocument]:
        """Re-rankea documentos usando cross-encoder"""
        
        if not self.cross_encoder or len(documents) <= 1:
            return documents
            
        try:
            # Preparar pares query-documento para el cross-encoder
            query_doc_pairs = [(query, doc.content[:512]) for doc in documents]  # Limitar longitud
            
            # Obtener scores del cross-encoder
            rerank_scores = self.cross_encoder.predict(query_doc_pairs)
            
            # Combinar con scores originales
            for i, doc in enumerate(documents):
                # Peso 70% cross-encoder, 30% score original
                doc.final_score = 0.7 * rerank_scores[i] + 0.3 * doc.final_score
                doc.confidence = min(doc.confidence + 0.1, 1.0)  # Bonus por re-ranking
                
            # Reordenar
            documents.sort(key=lambda x: x.final_score, reverse=True)
            
            logger.info(f"‚úÖ Re-ranking completado para {len(documents)} documentos")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error en re-ranking: {e}")
            
        return documents

    def _filter_and_diversify(self, documents: List[RetrievedDocument], top_k: int = 8) -> List[RetrievedDocument]:
        """Filtra y diversifica resultados finales"""
        
        if not documents:
            return []
            
        # Paso 1: Filtrar por calidad m√≠nima
        quality_threshold = 0.2
        quality_docs = [doc for doc in documents if doc.final_score > quality_threshold]
        
        if not quality_docs:
            quality_docs = documents[:3]  # Fallback a los 3 mejores
            
        # Paso 2: Diversificar por categor√≠a
        diversified_docs = []
        seen_categories = set()
        remaining_docs = quality_docs.copy()
        
        # Primero, tomar el mejor de cada categor√≠a
        for doc in remaining_docs:
            category = doc.metadata.get('category', 'general')
            if category not in seen_categories and len(diversified_docs) < top_k:
                diversified_docs.append(doc)
                seen_categories.add(category)
                
        # Luego, llenar con los mejores restantes
        for doc in remaining_docs:
            if doc not in diversified_docs and len(diversified_docs) < top_k:
                diversified_docs.append(doc)
                
        # Paso 3: Deduplicaci√≥n por contenido similar
        final_docs = []
        for doc in diversified_docs:
            is_duplicate = False
            for existing_doc in final_docs:
                # Verificar similitud de contenido
                content_similarity = self._calculate_text_similarity(doc.content, existing_doc.content)
                if content_similarity > 0.85:
                    is_duplicate = True
                    break
                    
            if not is_duplicate:
                final_docs.append(doc)
                
        return final_docs[:top_k]

    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """Calcula similitud textual para deduplicaci√≥n"""
        
        # Similitud simple basada en palabras comunes
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
            
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union) if union else 0.0


class EnhancedResponseGenerator:
    """Generador de respuestas mejorado y m√°s natural"""
    
    def __init__(self):
        self.response_templates = self._load_response_templates()
        self.conversation_context = {}
        
    def _load_response_templates(self) -> Dict[str, str]:
        """Carga templates de respuesta personalizados"""
        
        return {
            'greeting': """
¬°Hola! üòä Soy el asistente virtual de DUOC UC Plaza Norte. 
Estoy aqu√≠ para ayudarte con informaci√≥n sobre nuestros servicios, tr√°mites, ubicaciones y todo lo que necesites saber sobre la sede.

¬øEn qu√© puedo ayudarte hoy?
""",
            'location_info': """
üìç **{title}**

{content}

üí° **Informaci√≥n adicional:**
{additional_info}
""",
            'contact_info': """
üìû **Informaci√≥n de Contacto**

{content}

Para m√°s informaci√≥n puedes contactarnos en:
{contact_details}
""",
            'procedural': """
üìã **{title}**

{steps}

‚ö†Ô∏è **Importante:** {important_notes}

¬øNecesitas ayuda con alg√∫n paso espec√≠fico?
""",
            'not_found': """
No encontr√© informaci√≥n espec√≠fica sobre tu consulta en mi base de conocimientos actual.

Para obtener ayuda personalizada, te recomiendo:

üè¢ **Punto Estudiantil**
üìç Ubicaci√≥n: Piso 1, hall principal Plaza Norte
üïí Horario: Lunes a Viernes 8:30 - 17:30
üìû Tel: +56 2 2596 5000

¬øHay algo m√°s en lo que pueda ayudarte?
"""
        }

    def generate_enhanced_response(self, context: ResponseContext) -> Dict[str, Any]:
        """Genera respuesta mejorada basada en contexto"""
        
        if not context.retrieved_docs:
            return self._generate_fallback_response(context)
            
        # Determinar tipo de respuesta basado en contenido
        response_type = self._determine_response_type(context)
        
        # Generar respuesta seg√∫n el tipo
        if response_type == 'factual_direct':
            response = self._generate_factual_response(context)
        elif response_type == 'procedural':
            response = self._generate_procedural_response(context)
        elif response_type == 'location_contact':
            response = self._generate_location_contact_response(context)
        else:
            response = self._generate_conversational_response(context)
            
        # Enriquecer respuesta con contexto
        enhanced_response = self._enrich_response(response, context)
        
        # Agregar informaci√≥n de fuentes y confianza
        response_data = {
            "response": enhanced_response,
            "confidence": self._calculate_response_confidence(context),
            "sources": self._format_sources(context.retrieved_docs),
            "response_type": response_type,
            "follow_up_suggestions": self._generate_follow_up_suggestions(context)
        }
        
        return response_data

    def _determine_response_type(self, context: ResponseContext) -> str:
        """Determina el tipo de respuesta m√°s apropiado"""
        
        query_lower = context.query.lower()
        
        # Patrones para tipos de respuesta
        location_patterns = ['d√≥nde', 'ubicaci√≥n', 'direcci√≥n', 'c√≥mo llegar', 'encuentro', 'est√°']
        contact_patterns = ['tel√©fono', 'contacto', 'horario', 'llamar', 'correo', 'email']
        procedural_patterns = ['c√≥mo', 'pasos', 'proceso', 'tr√°mite', 'hacer', 'solicitar', 'obtener']
        factual_patterns = ['qu√© es', 'cu√°l es', 'informaci√≥n', 'explica', 'describe']
        
        # Contar coincidencias
        location_count = sum(1 for pattern in location_patterns if pattern in query_lower)
        contact_count = sum(1 for pattern in contact_patterns if pattern in query_lower)
        procedural_count = sum(1 for pattern in procedural_patterns if pattern in query_lower)
        factual_count = sum(1 for pattern in factual_patterns if pattern in query_lower)
        
        # Verificar contenido de documentos recuperados
        has_location_info = any('ubicaci√≥n' in doc.content.lower() or 'piso' in doc.content.lower() 
                               for doc in context.retrieved_docs[:3])
        has_contact_info = any(re.search(r'\+?56\s?2?\s?\d{4}', doc.content) 
                              for doc in context.retrieved_docs[:3])
        has_steps = any('paso' in doc.content.lower() or 'proceso' in doc.content.lower() 
                       for doc in context.retrieved_docs[:3])
        
        # Determinar tipo
        if (location_count >= 1 or contact_count >= 1) and (has_location_info or has_contact_info):
            return 'location_contact'
        elif procedural_count >= 1 or has_steps:
            return 'procedural'
        elif factual_count >= 1:
            return 'factual_direct'
        else:
            return 'conversational'

    def _generate_factual_response(self, context: ResponseContext) -> str:
        """Genera respuesta factual directa"""
        
        # Tomar los mejores documentos
        best_docs = context.retrieved_docs[:3]
        
        # Extraer informaci√≥n m√°s relevante
        content_parts = []
        for doc in best_docs:
            # Buscar p√°rrafo m√°s relevante
            paragraphs = [p.strip() for p in doc.content.split('\n') if p.strip()]
            best_paragraph = ""
            
            for paragraph in paragraphs:
                if len(paragraph) > 50 and any(word in paragraph.lower() for word in context.query.lower().split()):
                    best_paragraph = paragraph
                    break
                    
            if best_paragraph:
                content_parts.append(best_paragraph)
            elif paragraphs:
                content_parts.append(paragraphs[0])
                
        # Construir respuesta
        if content_parts:
            response = f"Seg√∫n la informaci√≥n que tengo sobre {context.category}:\n\n"
            
            for i, content in enumerate(content_parts[:2]):  # M√°ximo 2 fuentes
                response += f"‚Ä¢ {content}\n\n"
                
            response += "¬øNecesitas informaci√≥n m√°s espec√≠fica sobre alg√∫n aspecto?"
        else:
            response = "No encontr√© informaci√≥n espec√≠fica sobre tu consulta."
            
        return response

    def _generate_procedural_response(self, context: ResponseContext) -> str:
        """Genera respuesta procedimental con pasos"""
        
        best_doc = context.retrieved_docs[0] if context.retrieved_docs else None
        
        if not best_doc:
            return "No encontr√© informaci√≥n sobre el proceso que consultas."
            
        content = best_doc.content
        
        # Buscar pasos o informaci√≥n estructurada
        steps = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            # Detectar l√≠neas que parecen pasos
            if (re.match(r'^\d+\.', line) or  # 1. Paso
                re.match(r'^-\s+', line) or   # - Item
                'paso' in line.lower() or
                'requisito' in line.lower()):
                steps.append(line)
                
        # Construir respuesta
        response = f"Para {context.query.lower()}, estos son los pasos a seguir:\n\n"
        
        if steps:
            for step in steps[:5]:  # M√°ximo 5 pasos
                response += f"‚Ä¢ {step}\n"
        else:
            # Fallback: usar contenido general
            paragraphs = [p.strip() for p in content.split('\n') if p.strip()]
            for paragraph in paragraphs[:2]:
                response += f"‚Ä¢ {paragraph}\n"
                
        response += "\n¬øTe gustar√≠a que te ayude con alg√∫n paso espec√≠fico?"
        
        return response

    def _generate_location_contact_response(self, context: ResponseContext) -> str:
        """Genera respuesta con informaci√≥n de ubicaci√≥n y contacto"""
        
        location_info = []
        contact_info = []
        
        for doc in context.retrieved_docs[:3]:
            content = doc.content
            metadata = doc.metadata
            
            # Extraer informaci√≥n de ubicaci√≥n
            location_patterns = [
                r'piso\s+\d+',
                r'ubicado\s+en[\s\w\d,.-]+',
                r'sector\s+[\w\s]+',
                r'direcci√≥n[\s:]*[\w\s\d,.-]+',
            ]
            
            for pattern in location_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                location_info.extend(matches)
                
            # Extraer informaci√≥n de contacto
            contact_patterns = [
                r'\+?56\s?2?\s?\d{4}\s?\d{4}',
                r'[\w\.-]+@duoc\.cl',
                r'\d{1,2}:\d{2}.*\d{1,2}:\d{2}',
                r'horario[\s:]*[lunes|martes|mi√©rcoles|jueves|viernes|s√°bado|domingo|\d]+'
            ]
            
            for pattern in contact_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                contact_info.extend(matches)
                
        # Construir respuesta
        response = ""
        
        if location_info:
            response += "üìç **Ubicaci√≥n:**\n"
            for info in set(location_info[:3]):  # Deduplicar y limitar
                response += f"‚Ä¢ {info}\n"
            response += "\n"
            
        if contact_info:
            response += "üìû **Informaci√≥n de Contacto:**\n"
            for info in set(contact_info[:3]):  # Deduplicar y limitar
                response += f"‚Ä¢ {info}\n"
            response += "\n"
            
        if not response:
            # Fallback con informaci√≥n general
            best_doc = context.retrieved_docs[0]
            response = f"Informaci√≥n sobre {context.category}:\n\n{best_doc.content[:300]}...\n\n"
            
        response += "¬øNecesitas ayuda para llegar o informaci√≥n adicional?"
        
        return response

    def _generate_conversational_response(self, context: ResponseContext) -> str:
        """Genera respuesta conversacional natural"""
        
        # Combinar informaci√≥n de m√∫ltiples documentos
        combined_info = []
        
        for doc in context.retrieved_docs[:2]:
            # Buscar p√°rrafo m√°s relevante
            paragraphs = [p.strip() for p in doc.content.split('\n\n') if len(p.strip()) > 100]
            
            if paragraphs:
                best_paragraph = paragraphs[0]
                combined_info.append(best_paragraph)
                
        # Construir respuesta conversacional
        response = "Bas√°ndome en la informaci√≥n que tengo:\n\n"
        
        for info in combined_info:
            response += f"{info}\n\n"
            
        response += "¬øTe resulta √∫til esta informaci√≥n? ¬øHay algo espec√≠fico que te gustar√≠a saber m√°s?"
        
        return response

    def _generate_fallback_response(self, context: ResponseContext) -> Dict[str, Any]:
        """Genera respuesta cuando no hay documentos relevantes"""
        
        response = self.response_templates['not_found']
        
        return {
            "response": response,
            "confidence": 0.2,
            "sources": [],
            "response_type": "fallback",
            "follow_up_suggestions": [
                "¬øPuedes reformular tu pregunta?",
                "¬øNecesitas ayuda con servicios espec√≠ficos de Plaza Norte?",
                "¬øTe interesa informaci√≥n sobre tr√°mites estudiantiles?"
            ]
        }

    def _enrich_response(self, response: str, context: ResponseContext) -> str:
        """Enriquece respuesta con contexto adicional"""
        
        # Agregar informaci√≥n contextual si es relevante
        enriched_response = response
        
        # Si es Plaza Norte espec√≠fico, agregar info de sede
        if any('plaza norte' in doc.metadata.get('category', '').lower() for doc in context.retrieved_docs[:2]):
            enriched_response += "\n\nüìå Esta informaci√≥n es espec√≠fica para la sede Plaza Norte."
            
        # Agregar horarios generales si no est√°n incluidos
        if 'horario' in context.query.lower() and not re.search(r'\d{1,2}:\d{2}', response):
            enriched_response += "\n\n‚è∞ Horario general de atenci√≥n: Lunes a Viernes 8:30 - 17:30"
            
        return enriched_response

    def _calculate_response_confidence(self, context: ResponseContext) -> float:
        """Calcula confianza en la respuesta generada"""
        
        if not context.retrieved_docs:
            return 0.2
            
        # Factor 1: Confianza promedio de documentos
        avg_doc_confidence = sum(doc.confidence for doc in context.retrieved_docs[:3]) / min(len(context.retrieved_docs), 3)
        
        # Factor 2: Relevancia de los mejores documentos
        top_scores = [doc.final_score for doc in context.retrieved_docs[:2]]
        avg_relevance = sum(top_scores) / len(top_scores) if top_scores else 0
        
        # Factor 3: Consistencia entre fuentes
        consistency_bonus = 0.1 if len(context.retrieved_docs) >= 2 else 0
        
        # Factor 4: Categor√≠a espec√≠fica
        category_bonus = 0.1 if context.category != 'general' else 0
        
        total_confidence = (avg_doc_confidence * 0.5 + 
                           avg_relevance * 0.3 + 
                           consistency_bonus + 
                           category_bonus)
        
        return min(total_confidence, 0.95)  # M√°ximo 95% de confianza

    def _format_sources(self, documents: List[RetrievedDocument]) -> List[Dict[str, Any]]:
        """Formatea fuentes para la respuesta"""
        
        sources = []
        
        for doc in documents[:3]:  # M√°ximo 3 fuentes
            source_info = {
                "content_preview": doc.content[:150] + "..." if len(doc.content) > 150 else doc.content,
                "category": doc.metadata.get('category', 'general'),
                "confidence": doc.confidence,
                "relevance": doc.final_score,
                "source_url": doc.metadata.get('source', ''),
                "last_updated": doc.metadata.get('extraction_timestamp', '')
            }
            sources.append(source_info)
            
        return sources

    def _generate_follow_up_suggestions(self, context: ResponseContext) -> List[str]:
        """Genera sugerencias de seguimiento"""
        
        suggestions = []
        
        # Basado en categor√≠a
        category_suggestions = {
            'tne': [
                "¬øNecesitas saber c√≥mo renovar tu TNE?",
                "¬øQuieres informaci√≥n sobre horarios de validaci√≥n?"
            ],
            'certificados': [
                "¬øNecesitas ayuda con el proceso de solicitud?",
                "¬øQuieres saber sobre otros tipos de certificados?"
            ],
            'biblioteca': [
                "¬øTe interesa saber sobre recursos digitales?",
                "¬øNecesitas ayuda para reservar espacios de estudio?"
            ],
            'deportes': [
                "¬øQuieres informaci√≥n sobre inscripciones?",
                "¬øTe interesan los horarios del gimnasio?"
            ]
        }
        
        category = context.category
        if category in category_suggestions:
            suggestions.extend(category_suggestions[category])
        else:
            # Sugerencias generales
            suggestions = [
                "¬øHay algo m√°s espec√≠fico que te gustar√≠a saber?",
                "¬øNecesitas ayuda con servicios de la sede Plaza Norte?",
                "¬øTe interesa informaci√≥n sobre horarios de atenci√≥n?"
            ]
            
        return suggestions[:3]  # M√°ximo 3 sugerencias


class EnhancedRAGSystem:
    """Sistema RAG mejorado completo"""
    
    def __init__(self):
        self.retriever = AdvancedRetriever()
        self.response_generator = EnhancedResponseGenerator()
        self.topic_classifier = TopicClassifier()
        self.is_indexed = False
        
        logger.info("‚úÖ Sistema RAG mejorado inicializado")

    def index_knowledge_base(self, force_reindex: bool = False):
        """Indexa la base de conocimiento existente"""
        
        if self.is_indexed and not force_reindex:
            return
            
        try:
            # Obtener documentos del sistema RAG existente
            documents = self._extract_existing_documents()
            
            if not documents:
                logger.warning("‚ö†Ô∏è No se encontraron documentos para indexar")
                return
                
            # Indexar documentos
            self.retriever.index_documents(documents)
            self.is_indexed = True
            
            logger.info(f"‚úÖ Base de conocimiento indexada: {len(documents)} documentos")
            
        except Exception as e:
            logger.error(f"‚ùå Error indexando base de conocimiento: {e}")

    def _extract_existing_documents(self) -> List[Dict[str, Any]]:
        """Extrae documentos del sistema RAG existente"""
        
        documents = []
        
        try:
            # Intentar obtener documentos de Chroma DB si est√° disponible
            if hasattr(rag_engine, 'collection') and rag_engine.collection:
                # Obtener todos los documentos
                result = rag_engine.collection.get()
                
                if result and 'documents' in result:
                    for i, doc in enumerate(result['documents']):
                        metadata = result.get('metadatas', [{}])[i] if i < len(result.get('metadatas', [])) else {}
                        
                        documents.append({
                            'content': doc,
                            'metadata': metadata
                        })
                        
                    logger.info(f"‚úÖ Extra√≠dos {len(documents)} documentos de Chroma DB")
                    
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error extrayendo documentos de Chroma DB: {e}")
            
        # Fallback: crear documentos de muestra si no hay datos
        if not documents:
            documents = self._create_sample_documents()
            
        return documents

    def _create_sample_documents(self) -> List[Dict[str, Any]]:
        """Crea documentos de muestra para testing"""
        
        sample_docs = [
            {
                'content': """
                La TNE (Tarjeta Nacional Estudiantil) se puede obtener y validar en:
                
                Ubicaci√≥n: Punto Estudiantil, Piso 1, Hall Principal Plaza Norte
                Horario: Lunes a Viernes 8:30 - 17:30
                Documentos requeridos: Carnet de identidad y certificado de alumno regular
                
                Para primera vez, debes llenar el formulario TNE y presentar una foto tama√±o carnet.
                """,
                'metadata': {
                    'category': 'tne',
                    'priority': 'high',
                    'is_plaza_norte': True,
                    'source': 'sistema_interno'
                }
            },
            {
                'content': """
                Biblioteca Plaza Norte est√° ubicada en el Piso 1, Ala Este.
                
                Horarios de atenci√≥n:
                - Lunes a Jueves: 8:00 - 21:00
                - Viernes: 8:00 - 18:00
                - S√°bados: 9:00 - 14:00
                
                Servicios disponibles: Pr√©stamo de libros, salas de estudio, computadores, impresi√≥n.
                Contacto: biblioteca.plazanorte@duoc.cl
                """,
                'metadata': {
                    'category': 'biblioteca',
                    'priority': 'high',
                    'is_plaza_norte': True,
                    'source': 'sistema_interno'
                }
            }
        ]
        
        return sample_docs

    def query(self, question: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """Procesa consulta con el sistema RAG mejorado"""
        
        # Asegurar que la base de conocimiento est√© indexada
        if not self.is_indexed:
            self.index_knowledge_base()
            
        try:
            # Paso 1: Clasificar consulta
            classification = self.topic_classifier.classify_topic(question)
            category = classification.get('category', 'general')
            
            # Paso 2: Retrieve documentos relevantes
            retrieved_docs = self.retriever.retrieve_hybrid(question, top_k=8)
            
            # Paso 3: Crear contexto de respuesta
            context = ResponseContext(
                query=question,
                category=category,
                retrieved_docs=retrieved_docs,
                conversation_history=conversation_history or []
            )
            
            # Paso 4: Generar respuesta
            response = self.response_generator.generate_enhanced_response(context)
            
            # Paso 5: Enriquecer con metadata del sistema
            response.update({
                "query_classification": classification,
                "retrieval_method": "hybrid_advanced",
                "documents_retrieved": len(retrieved_docs),
                "processing_timestamp": datetime.now().isoformat()
            })
            
            logger.info(f"‚úÖ Consulta procesada: '{question[:50]}...' -> Confianza: {response['confidence']:.3f}")
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando consulta: {e}")
            
            return {
                "response": "Lo siento, experiment√© un error procesando tu consulta. ¬øPodr√≠as intentar reformularla?",
                "confidence": 0.0,
                "sources": [],
                "error": str(e)
            }

    def analyze_system_performance(self) -> Dict[str, Any]:
        """Analiza el rendimiento del sistema RAG"""
        
        performance_data = {
            "indexed_documents": len(self.retriever.documents_corpus) if self.is_indexed else 0,
            "embedding_models": list(self.retriever.embedders.keys()),
            "tfidf_features": self.retriever.tfidf_matrix.shape[1] if self.retriever.tfidf_matrix is not None else 0,
            "faiss_index_size": self.retriever.faiss_index.ntotal if self.retriever.faiss_index else 0,
            "cross_encoder_available": self.retriever.cross_encoder is not None,
            "system_status": "ready" if self.is_indexed else "not_indexed"
        }
        
        return performance_data


# Funci√≥n para integrar el sistema mejorado
def integrate_enhanced_rag():
    """Integra el sistema RAG mejorado con el sistema existente"""
    
    try:
        # Crear instancia del sistema mejorado
        enhanced_system = EnhancedRAGSystem()
        
        # Indexar base de conocimiento existente
        enhanced_system.index_knowledge_base()
        
        # Analizar performance
        performance = enhanced_system.analyze_system_performance()
        
        logger.info("üöÄ Sistema RAG mejorado integrado exitosamente")
        logger.info(f"üìä Performance: {performance}")
        
        return enhanced_system
        
    except Exception as e:
        logger.error(f"‚ùå Error integrando sistema RAG mejorado: {e}")
        return None


if __name__ == "__main__":
    # Test del sistema mejorado
    enhanced_rag = integrate_enhanced_rag()
    
    if enhanced_rag:
        # Test queries
        test_queries = [
            "¬øD√≥nde puedo obtener mi TNE?",
            "¬øCu√°les son los horarios de la biblioteca?",
            "¬øC√≥mo solicito un certificado de alumno regular?",
            "¬øD√≥nde est√° ubicado el Punto Estudiantil?"
        ]
        
        print("\nüî¨ TESTING SISTEMA RAG MEJORADO")
        print("="*50)
        
        for query in test_queries:
            print(f"\n‚ùì Consulta: {query}")
            response = enhanced_rag.query(query)
            print(f"ü§ñ Respuesta: {response['response'][:200]}...")
            print(f"üìä Confianza: {response['confidence']:.3f}")
            print(f"üìö Fuentes: {len(response['sources'])}")