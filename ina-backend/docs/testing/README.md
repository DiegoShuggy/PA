# ğŸ§ª GUÃA DE PRUEBAS RAG - Sistema InA

**Ãšltima ActualizaciÃ³n:** 2 de Diciembre 2025  
**VersiÃ³n:** 1.0

---

## ğŸ“‹ CONTENIDO DE ESTA CARPETA

### ğŸ“„ Archivos de Consultas:

1. **`CONSULTAS_PRUEBA_RAG_PURO.md`** â­â­
   - 25 consultas estratÃ©gicas
   - Nivel: Medio
   - Tiempo: ~20 minutos
   - **PropÃ³sito:** Baseline inicial del sistema

2. **`LISTA_CONSULTAS_PRUEBA.md`** â­â­â­
   - 25 consultas detalladas
   - Nivel: Alto
   - Tiempo: ~20 minutos
   - **PropÃ³sito:** ValidaciÃ³n post-FASE 3

3. **`CONSULTAS_RAPIDAS.md`** â­
   - 25 consultas (versiÃ³n simplificada)
   - Nivel: FÃ¡cil
   - Tiempo: ~10 minutos
   - **PropÃ³sito:** Testing rÃ¡pido copy-paste

4. **`CONSULTAS_ADICIONALES_RAG_PURO_AVANZADAS.md`** â­â­â­â­â­ ğŸ†•
   - 50 consultas complejas
   - Nivel: Avanzado-MÃ¡ximo
   - Tiempo: ~40 minutos
   - **PropÃ³sito:** LÃ­mites del sistema, gaps documentales

5. **`CONSULTAS_CONVERSACIONALES_SIN_TEMPLATES.md`** â­â­â­â­ ğŸ†•
   - 40 consultas en lenguaje natural
   - Nivel: Realista
   - Tiempo: ~30 minutos
   - **PropÃ³sito:** Robustez con lenguaje informal

6. **`RESUMEN_COMPLETO_CONSULTAS_RAG.md`** ğŸ“Š ğŸ†•
   - ConsolidaciÃ³n de todos los archivos
   - **PropÃ³sito:** VisiÃ³n global del sistema de pruebas

---

### ğŸ Scripts de AutomatizaciÃ³n:

7. **`test_rag_automatico.py`** ğŸ¤– ğŸ†•
   - Script Python para testing automatizado
   - Genera reportes Markdown y JSON
   - **PropÃ³sito:** EjecuciÃ³n masiva y anÃ¡lisis

---

## ğŸš€ INICIO RÃPIDO

### OpciÃ³n 1: Prueba Manual (10 minutos)

```bash
# 1. Inicia el servidor backend
cd c:\Users\SSDD1\Documents\GitHub\Proyecto_InA\ina-backend
uvicorn app.main:app --reload --port 8000

# 2. Abre el frontend (en otra terminal)
cd ../ina-frontend
npm run dev

# 3. Abre CONSULTAS_RAPIDAS.md
# 4. Copia y pega consultas en el chat
# 5. Observa los resultados
```

**Ventajas:**
- âœ… RÃ¡pido y sencillo
- âœ… Feedback visual inmediato
- âœ… Ideal para exploraciÃ³n

**Desventajas:**
- âŒ Manual y lento para muchas consultas
- âŒ No genera reportes automÃ¡ticos

---

### OpciÃ³n 2: Prueba Automatizada (5-70 minutos)

```bash
# 1. Inicia el servidor backend
cd c:\Users\SSDD1\Documents\GitHub\Proyecto_InA\ina-backend
uvicorn app.main:app --reload --port 8000

# 2. Crea directorio de resultados
mkdir test_results

# 3. Ejecuta el script de testing (en otra terminal)
python scripts/testing/test_rag_automatico.py

# 4. Sigue el menÃº interactivo
# 5. Revisa los reportes en test_results/
```

**Ventajas:**
- âœ… EjecuciÃ³n masiva automatizada
- âœ… Reportes detallados generados
- âœ… AnÃ¡lisis estadÃ­stico incluido
- âœ… Ideal para evaluaciÃ³n completa

**Desventajas:**
- âŒ Requiere esperar a que termine
- âŒ Sin feedback visual del chat

---

## ğŸ“Š ESTRUCTURA DE PRUEBAS

### FASE 1: Baseline (25-50 consultas, ~30 min)
**Archivos:** `CONSULTAS_PRUEBA_RAG_PURO.md` + `LISTA_CONSULTAS_PRUEBA.md`

**Objetivo:** Establecer lÃ­nea base de rendimiento

**QuÃ© evaluar:**
- âœ… CategorizaciÃ³n correcta
- âœ… Templates se activan apropiadamente
- âœ… RAG recupera informaciÃ³n relevante
- âœ… Respuestas coherentes y Ãºtiles
- âœ… Tiempo de respuesta <4 segundos

**MÃ©trica objetivo:** 70%+ de Ã©xito

---

### FASE 2: Avanzado (50 consultas, ~40 min)
**Archivo:** `CONSULTAS_ADICIONALES_RAG_PURO_AVANZADAS.md`

**Objetivo:** Identificar lÃ­mites y gaps

**QuÃ© evaluar:**
- âœ… Manejo de consultas complejas
- âœ… Respuestas sin templates disponibles
- âœ… CombinaciÃ³n de mÃºltiples fuentes
- âœ… AdmisiÃ³n de falta de informaciÃ³n
- âœ… Sugerencias proactivas

**MÃ©trica objetivo:** 60%+ de Ã©xito (mÃ¡s bajo por complejidad)

---

### FASE 3: Conversacional (40 consultas, ~30 min)
**Archivo:** `CONSULTAS_CONVERSACIONALES_SIN_TEMPLATES.md`

**Objetivo:** Validar robustez con lenguaje real

**QuÃ© evaluar:**
- âœ… ComprensiÃ³n de lenguaje informal
- âœ… Tolerancia a errores ortogrÃ¡ficos
- âœ… DetecciÃ³n de urgencias emocionales
- âœ… Derivaciones apropiadas
- âœ… Tono empÃ¡tico pero profesional

**MÃ©trica objetivo:** 70%+ comprensiÃ³n, 60%+ utilidad

---

### FASE 4: CrÃ­ticos (10 consultas seleccionadas, ~10 min)
**Archivo:** Subset de `CONSULTAS_CONVERSACIONALES_SIN_TEMPLATES.md`

**Consultas prioritarias:**
- #21: Ansiedad por exÃ¡menes
- #24: Colapso emocional
- #27: DepresiÃ³n
- #28: Acoso
- #29: Crisis financiera
- #30: Conflicto con docente

**Objetivo:** Garantizar manejo seguro de casos sensibles

**MÃ©trica objetivo:** 100% de derivaciones correctas

---

## ğŸ“Š MÃ‰TRICAS CLAVE

### 1. Tasa de ComprensiÃ³n
```
ComprensiÃ³n = (Consultas Entendidas / Total) Ã— 100
```
- âœ… Excelente: >85%
- âš ï¸ Aceptable: 70-85%
- âŒ Deficiente: <70%

---

### 2. Tasa de Utilidad
```
Utilidad = (Respuestas Ãštiles / Consultas Entendidas) Ã— 100
```
- âœ… Excelente: >80%
- âš ï¸ Aceptable: 65-80%
- âŒ Deficiente: <65%

---

### 3. Tasa de Hallucinations
```
Hallucinations = (Info Inventada / Total Respuestas) Ã— 100
```
- âœ… Excelente: <5%
- âš ï¸ Aceptable: 5-10%
- âŒ Deficiente: >10%

---

### 4. Tiempo de Respuesta
- âœ… Excelente: <2 segundos
- âš ï¸ Aceptable: 2-4 segundos
- âŒ Deficiente: >4 segundos

---

## ğŸ“ FORMATO DE EVALUACIÃ“N MANUAL

Para cada consulta, registra:

```markdown
### Consulta #X: [CategorÃ­a]
**Query:** [texto exacto]

**Respuesta del Sistema:**
[pegar respuesta completa]

**EvaluaciÃ³n:**
- [ ] âœ… / âŒ ComprensiÃ³n correcta
- [ ] âœ… / âŒ Respuesta Ãºtil
- [ ] âœ… / âŒ Sin hallucinations
- [ ] âœ… / âŒ Tono apropiado
- [ ] â­â­â­â­â­ Calidad: [1-5]

**Observaciones:**
[comentarios especÃ­ficos]

**Sugerencias:**
[ ] Crear template
[ ] Mejorar documentaciÃ³n
[ ] Ajustar chunking
[ ] Otro: _________
```

---

## ğŸ¯ CASOS DE USO

### 1. Desarrollo Diario
**Usa:** `CONSULTAS_RAPIDAS.md` (Quick Test: 10 consultas)
**Frecuencia:** Diaria
**Tiempo:** 5 minutos
**Objetivo:** ValidaciÃ³n rÃ¡pida despuÃ©s de cambios

---

### 2. EvaluaciÃ³n Semanal
**Usa:** Automatizado con Script (OpciÃ³n 5: Quick Test)
**Frecuencia:** Semanal
**Tiempo:** 10 minutos
**Objetivo:** Monitoreo de regresiones

---

### 3. Release Testing
**Usa:** Automatizado con Script (OpciÃ³n 4: Todas las suites)
**Frecuencia:** Antes de cada release
**Tiempo:** 70 minutos
**Objetivo:** ValidaciÃ³n exhaustiva

---

### 4. InvestigaciÃ³n de Bugs
**Usa:** Manual con archivos especÃ­ficos
**Frecuencia:** SegÃºn necesidad
**Tiempo:** Variable
**Objetivo:** Debug de problemas especÃ­ficos

---

## ğŸš¨ SEÃ‘ALES DE ALERTA

### CrÃ­ticas (Requieren acciÃ³n inmediata):
- âŒ Tasa de Ã©xito <60%
- âŒ Hallucinations >15%
- âŒ Tiempo promedio >5 segundos
- âŒ Fallos en casos emocionales crÃ­ticos
- âŒ Derivaciones incorrectas en salud mental

### Importantes (Requieren atenciÃ³n):
- âš ï¸ Tasa de Ã©xito 60-70%
- âš ï¸ Hallucinations 10-15%
- âš ï¸ Tiempo promedio 4-5 segundos
- âš ï¸ CategorizaciÃ³n incorrecta frecuente
- âš ï¸ QR codes no generados cuando deberÃ­an

### Menores (Mejora continua):
- ğŸ” Respuestas genÃ©ricas frecuentes
- ğŸ” Fuentes poco relevantes recuperadas
- ğŸ” Tono inconsistente
- ğŸ” Falta de proactividad en sugerencias

---

## ğŸ“š DOCUMENTACIÃ“N RELACIONADA

### En este repositorio:
- `RESUMEN_COMPLETO_CONSULTAS_RAG.md` - VisiÃ³n consolidada
- `../../docs/ANALISIS_COMPLETO_RAG_27NOV2025.md` - AnÃ¡lisis tÃ©cnico del sistema
- `../../docs/MEJORAS_RAG_IMPLEMENTADAS.md` - Historial de mejoras

### Templates del sistema:
- `../../app/templates.py` - DefiniciÃ³n de todos los templates

### ConfiguraciÃ³n RAG:
- `../../app/rag.py` - Sistema RAG principal
- `../../app/enhanced_rag_system.py` - VersiÃ³n mejorada
- `../../app/intelligent_response_system.py` - Orquestador de respuestas

---

## ğŸ› ï¸ TROUBLESHOOTING

### Error: "Connection refused"
**Causa:** Servidor no estÃ¡ corriendo  
**SoluciÃ³n:**
```bash
cd c:\Users\SSDD1\Documents\GitHub\Proyecto_InA\ina-backend
uvicorn app.main:app --reload --port 8000
```

---

### Error: "ModuleNotFoundError"
**Causa:** Dependencias no instaladas  
**SoluciÃ³n:**
```bash
pip install requests
# O instala todas las dependencias:
pip install -r requirements.txt
```

---

### Error: "Timeout despuÃ©s de 30s"
**Causa:** Consulta muy compleja o sistema sobrecargado  
**SoluciÃ³n:**
- Verifica que Ollama estÃ© corriendo
- Revisa los logs del servidor
- Considera aumentar el timeout en el script

---

### Resultados inconsistentes entre ejecuciones
**Causa:** Naturaleza probabilÃ­stica del LLM  
**SoluciÃ³n:** Normal - ejecuta mÃºltiples veces para promedios

---

## ğŸ“ˆ ROADMAP DE MEJORAS

### Corto Plazo (1-2 semanas):
- [ ] Completar datos de consultas en `test_rag_automatico.py`
- [ ] Agregar mÃ¡s consultas conversacionales chilenas
- [ ] Implementar sistema de scoring automÃ¡tico
- [ ] Crear dashboard visual de mÃ©tricas

### Mediano Plazo (1 mes):
- [ ] IntegraciÃ³n con CI/CD
- [ ] Testing A/B de mejoras del RAG
- [ ] HistÃ³rico de mÃ©tricas por versiÃ³n
- [ ] Alertas automÃ¡ticas de regresiones

### Largo Plazo (3+ meses):
- [ ] Testing de carga con mÃºltiples usuarios
- [ ] Feedback loop con usuarios reales
- [ ] Machine learning para detectar patrones de fallo
- [ ] OptimizaciÃ³n automÃ¡tica de parÃ¡metros

---

## ğŸ¤ CONTRIBUIR

### Agregar nuevas consultas:
1. Edita el archivo Markdown correspondiente
2. Sigue el formato existente
3. Incluye nivel de dificultad
4. Especifica si tiene template o no

### Mejorar el script de testing:
1. Modifica `test_rag_automatico.py`
2. MantÃ©n compatibilidad con formato actual
3. Documenta cambios significativos

---

## ğŸ“ CONTACTO Y SOPORTE

**Equipo InA - Duoc UC Plaza Norte**

- ğŸ“§ Email: soporte@duoc.cl
- ğŸ“± Slack: #ina-desarrollo
- ğŸ“Š Jira: Proyecto INA
- ğŸ“– Wiki: https://wiki.duoc.cl/ina

---

## âœ… CHECKLIST RÃPIDO

Antes de cada release, verifica:

- [ ] Ejecutar suite completa de pruebas (140 consultas)
- [ ] Tasa de Ã©xito >70% en todas las fases
- [ ] Tiempo promedio <4 segundos
- [ ] Hallucinations <5%
- [ ] Casos crÃ­ticos 100% derivados correctamente
- [ ] Documentar gaps encontrados
- [ ] Priorizar templates a crear
- [ ] Actualizar documentaciÃ³n si hay cambios

---

## ğŸ“ CONCLUSIÃ“N

Este sistema de pruebas te permite:

âœ… **Validar** la calidad del RAG de forma objetiva  
âœ… **Identificar** Ã¡reas de mejora prioritarias  
âœ… **Monitorear** regresiones en cada cambio  
âœ… **Garantizar** experiencia de usuario consistente  
âœ… **Optimizar** basado en datos reales  

**El Ã©xito se mide en estudiantes ayudados, no en mÃ©tricas tÃ©cnicas aisladas.**

---

**Â¡Comienza ahora y construyamos juntos un InA que verdaderamente ayude! ğŸš€**

---

**VersiÃ³n:** 1.0  
**Fecha:** 2 de Diciembre 2025  
**Sistema:** InA - Duoc UC Plaza Norte
